{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# FX AI Analytics — Exploratory Notebook\n",
        "\n",
        "This notebook demonstrates how to programmatically use functions from `app.py` without Streamlit UI: load data, train models, calculate news and events, get the final signal and visualize price and ATR(14).\n",
        "\n",
        "Below are the steps: imports, instrument configuration, calculations and charts, and at the end — text recommendations and possible bottlenecks of the current approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "sys.path.append(os.path.abspath(\".\"))\n",
        "\n",
        "from app import (\n",
        "    load_price_data,\n",
        "    add_features,\n",
        "    add_targets,\n",
        "    train_models,\n",
        "    compute_news_sentiment,\n",
        "    fetch_future_economic_events,\n",
        "    score_future_events,\n",
        "    detect_patterns,\n",
        "    build_price_chart,\n",
        "    build_atr_chart,\n",
        "    build_prediction_chart,\n",
        "    build_classification_chart,\n",
        "    build_classification_comparison_chart,\n",
        "    combine_signals,\n",
        "    get_atr_volatility_info,\n",
        "    enrich_signals_with_atr,\n",
        "    get_signals_for_ticker,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Instrument Configuration\n",
        "\n",
        "Set the ticker, human-readable name, history depth and timeframe. The profile (conservative/aggressive, etc.) can be left as `None`, then default settings from `INSTRUMENT_SETTINGS` inside `app.py` will be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ticker = \"EURUSD=X\"\n",
        "instrument_name = \"EUR/USD\"\n",
        "years = 5\n",
        "interval = \"1d\"\n",
        "profile = None\n",
        "\n",
        "config = {\n",
        "    \"ticker\": ticker,\n",
        "    \"instrument_name\": instrument_name,\n",
        "    \"years\": years,\n",
        "    \"interval\": interval,\n",
        "    \"profile\": profile,\n",
        "}\n",
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Quick Unified Pipeline Call\n",
        "\n",
        "Using the high-level function `get_signals_for_ticker`, which internally:\n",
        "- loads price history via `yfinance`;\n",
        "- builds features, targets and trains models;\n",
        "- calculates news and future events;\n",
        "- builds patterns and integral scoring;\n",
        "- adds the latest ATR(14) values and volatility level to the signal.\n",
        "\n",
        "This is a convenient entry point for API and monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "signal_payload = get_signals_for_ticker(\n",
        "    ticker=ticker,\n",
        "    instrument_name=instrument_name,\n",
        "    years=years,\n",
        "    interval=interval,\n",
        "    profile=profile,\n",
        ")\n",
        "signal_payload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detailed Step-by-Step Pipeline\n",
        "\n",
        "Now let's repeat the key steps separately: data loading, feature engineering, model training and signal combination. This is useful for debugging and experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_raw = load_price_data(ticker, years=years, interval=interval)\n",
        "df_full = add_features(df_raw)\n",
        "atr_info = get_atr_volatility_info(df_full)\n",
        "\n",
        "horizon = 7\n",
        "lower_q = 0.33\n",
        "upper_q = 0.66\n",
        "\n",
        "df_model = add_targets(\n",
        "    df_full.copy(),\n",
        "    horizon=horizon,\n",
        "    lower_q=lower_q,\n",
        "    upper_q=upper_q,\n",
        ")\n",
        "model_data = train_models(df_model)\n",
        "metrics = model_data.get(\"metrics\")\n",
        "df_full.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. News, Events, Patterns and Final Signal\n",
        "\n",
        "Calculating news sentiment, future macro-events, price patterns and assembling the final integral signal, including ATR(14) information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "news_items, news_score = compute_news_sentiment(ticker, instrument_name)\n",
        "future_events = fetch_future_economic_events(days_ahead=7)\n",
        "future_events_score = score_future_events(future_events)\n",
        "patterns = detect_patterns(df_full[\"Close\"])\n",
        "\n",
        "model_weights = metrics.get(\"weights\") if metrics else None\n",
        "price_model = \"hybrid\" if metrics and \"hybrid\" in metrics else \"lstm\"\n",
        "cls_conf_threshold = 0.55\n",
        "\n",
        "signals = combine_signals(\n",
        "    df_full,\n",
        "    model_data,\n",
        "    news_score,\n",
        "    patterns,\n",
        "    future_events_score,\n",
        "    model_weights,\n",
        "    price_model,\n",
        "    classifier_override=None,\n",
        "    cls_conf_threshold=cls_conf_threshold,\n",
        ")\n",
        "signals = enrich_signals_with_atr(signals, atr_info)\n",
        "signals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization: Price, ATR(14), Forecasts and Classification\n",
        "\n",
        "Using the same plotting functions as inside the Streamlit app, but showing them directly in the notebook via Plotly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "price_fig = build_price_chart(df_full, instrument_name, patterns=patterns)\n",
        "atr_fig = build_atr_chart(df_full, instrument_name)\n",
        "pred_fig = build_prediction_chart(df_model, model_data, price_model, model_weights)\n",
        "class_fig = build_classification_chart(df_model, model_data, classifier_override=None)\n",
        "\n",
        "price_fig.show()\n",
        "atr_fig.show()\n",
        "pred_fig.show()\n",
        "class_fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if metrics:\n",
        "    comparison_fig = build_classification_comparison_chart(\n",
        "        df_model,\n",
        "        model_data,\n",
        "        model_weights,\n",
        "        cls_conf_threshold,\n",
        "    )\n",
        "    comparison_fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Recommendations and Possible Errors/Limitations of the Approach\n",
        "\n",
        "Below are several practical remarks on the current project:\n",
        "\n",
        "1. **Limited History**  \n",
        "   If `yfinance` returns little data (e.g. < 2 years for hourly timeframe), the model may not train well or fail with an error. Solution: increase history depth or switch to a higher timeframe.\n",
        "\n",
        "2. **Simplistic Features**  \n",
        "   Current features (RSI, MACD, returns, lags) are basic. For real production, it is worth adding: order book data, volatility surfaces, correlation with other assets (SPX, Gold, Oil), and more complex macro factors.\n",
        "\n",
        "3. **Simple Backtesting**  \n",
        "   The metrics shown in the logs (precision/recall, Sharpe) are calculated on a \"hold for 1 bar\" basis. Real trading requires accounting for spread, commissions, slippage, and execution delay. See `fx_ai_backtest.ipynb` for a more detailed backtest.\n",
        "\n",
        "4. **Pattern Recognition**  \n",
        "   The pattern recognition module (`detect_patterns`) is heuristic (local extrema). It may give false positives or miss complex figures. It is worth using specialized libraries or ML for pattern recognition.\n",
        "\n",
        "5. **News Sentiment**  \n",
        "   News analysis is based on simple keyword scoring. For better quality, LLM (BERT/GPT) should be used to analyze headlines and summaries, as implemented in the `compute_news_sentiment` stub (if external APIs are connected).\n",
        "\n",
        "6. **Model Retraining**  \n",
        "   Markets change. Models need to be retrained regularly (e.g. once a week/month). The current code trains the model from scratch on every call — this is acceptable for a prototype but slow for production. It is better to save/load weights (`joblib`/`pickle`).\n",
        "\n",
        "7. **Risk Management**  \n",
        "   The signal gives a direction (-1/0/1). The position size should be determined by the risk block (Risk Manager), which is not fully implemented in this notebook (only basic ATR logic). It is recommended to limit risk per trade (e.g. 1-2% of deposit).\n",
        "\n",
        "Good luck with your experiments!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

